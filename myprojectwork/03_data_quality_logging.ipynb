{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdba4bf6-17a8-4503-a487-72f5c5fe11f6",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"#row_number#\":73},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1764999902140}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit, count, when\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType\n",
    "from datetime import datetime\n",
    "\n",
    "# Load Silver table\n",
    "df = spark.table(\"churn_catalog.processed.customer_profiles\")\n",
    "\n",
    "issues = []\n",
    "\n",
    "#CHECK NULL VALUES\n",
    "null_counts = df.select(\n",
    "    [count(when(col(c).isNull(), c)).alias(c) for c in df.columns]\n",
    ").collect()[0].asDict()\n",
    "\n",
    "for column, null_value in null_counts.items():\n",
    "    if null_value > 0:\n",
    "        issues.append((column, \"NULL_VALUES\", null_value))\n",
    "\n",
    "# CHECK DUPLICATE CUSTOMER IDs\n",
    "duplicates = df.groupBy(\"customer_id\").count().filter(col(\"count\") > 1).count()\n",
    "if duplicates > 0:\n",
    "    issues.append((\"customer_id\", \"DUPLICATES_FOUND\", duplicates))\n",
    "\n",
    "# CHECK INVALID AGE\n",
    "invalid_age = df.filter((col(\"age\") <= 0) | (col(\"age\") >= 80)).count()\n",
    "if invalid_age > 0:\n",
    "    issues.append((\"age\", \"INVALID_RANGE\", invalid_age))\n",
    "\n",
    "# CHECK NEGATIVE BALANCE & SALARY\n",
    "negative_balance = df.filter(col(\"balance\") < 0).count()\n",
    "if negative_balance > 0:\n",
    "    issues.append((\"balance\", \"NEGATIVE_VALUES\", negative_balance))\n",
    "\n",
    "negative_salary = df.filter(col(\"estimated_salary\") < 0).count()\n",
    "if negative_salary > 0:\n",
    "    issues.append((\"estimated_salary\", \"NEGATIVE_VALUES\", negative_salary))\n",
    "\n",
    "# DEFINE EMPTY SCHEMA (IMPORTANT)\n",
    "log_schema = StructType([\n",
    "    StructField(\"timestamp\", TimestampType(), True),\n",
    "    StructField(\"column_name\", StringType(), True),\n",
    "    StructField(\"issue_type\", StringType(), True),\n",
    "    StructField(\"count\", IntegerType(), True),\n",
    "])\n",
    "\n",
    "#  CREATE LOG DATAFRAME\n",
    "if issues:\n",
    "    log_df = spark.createDataFrame(\n",
    "        [(datetime.now(), col_name, issue_type, count) \n",
    "         for col_name, issue_type, count in issues],\n",
    "        log_schema\n",
    "    )\n",
    "else:\n",
    "    log_df = spark.createDataFrame([], log_schema)  # EMPTY DATAFRAME\n",
    "\n",
    "# Show output\n",
    "display(log_df)\n",
    "\n",
    "# WRITE LOG TABLE\n",
    "log_df.write.format(\"delta\").mode(\"append\").saveAsTable(\n",
    "    \"churn_catalog.logs.data_quality\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebe1985d-0cb4-4ac1-ac5d-fdb6adfce6bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# DATA QUALITY SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b50bda8-00d9-41f0-b323-30ea31eaeeae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"DATA QUALITY SUMMARY\")\n",
    "print(f\"Total rows checked: {df.count()}\")\n",
    "print(f\"Null issues found: {sum([1 for i in issues if i[1]=='NULL_VALUES'])}\")\n",
    "print(f\"Duplicate customer_id count: {duplicates}\")\n",
    "print(f\"Invalid age rows: {invalid_age}\")\n",
    "print(f\"Negative balance rows: {negative_balance}\")\n",
    "print(f\"Negative salary rows: {negative_salary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7b8758f-e5ed-4391-a558-ac25d7d29c21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_data_quality_logging",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
